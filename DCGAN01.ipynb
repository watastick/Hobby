{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN01.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMIyIJixf5LXKkVD9mvDGh0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uaS69wV4HQ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6158446-8f1a-49c6-97ae-0bde580131a0"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Reshape\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import UpSampling2D, Convolution2D"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgX9al444iwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(input_dim=100, output_dim=1024))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(128*7*7))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Reshape((128, 7, 7), input_shape=(128*7*7,)))\n",
        "    model.add(UpSampling2D((2, 2)))\n",
        "    model.add(Convolution2D(64, 5, 5, border_mode='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(UpSampling2D((2, 2)))\n",
        "    model.add(Convolution2D(1, 5, 5, border_mode='same'))\n",
        "    model.add(Activation('tanh'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xgoHinN5Pff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd29b529-ecfe-492d-bf2c-21b48bf56679"
      },
      "source": [
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers import Flatten, Dropout"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1S5EPHB5xHT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_model():\n",
        "    model = Sequential()\n",
        "    model.add(Convolution2D(64, 5, 5,\n",
        "                            subsample=(2, 2),\n",
        "                            border_mode='same',\n",
        "                            input_shape=(1, 28, 28)))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Convolution2D(128, 5, 5, subsample=(2, 2)))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp1gmp0q52ub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2yeQUiC6CU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combine_images(generated_images):\n",
        "    total = generated_images.shape[0]\n",
        "    cols = int(math.sqrt(total))\n",
        "    rows = math.ceil(float(total)/cols)\n",
        "    width, height = generated_images.shape[2:]\n",
        "    combined_image = np.zeros((height*rows, width*cols),\n",
        "                              dtype=generated_images.dtype)\n",
        "\n",
        "    for index, image in enumerate(generated_images):\n",
        "        i = int(index/cols)\n",
        "        j = index % cols\n",
        "        combined_image[width*i:width*(i+1), height*j:height*(j+1)] = image[0, :, :]\n",
        "    return combined_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHastMol6F0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from keras.datasets import  mnist\n",
        "from keras.optimizers import  Adam\n",
        "from PIL import Image\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCH = 20\n",
        "GENERATED_IMAGE_PATH = 'generated_images/' # 生成画像の保存先\n",
        "\n",
        "def train():\n",
        "    (X_train, y_train), (_, _) = mnist.load_data()\n",
        "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
        "    X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1], X_train.shape[2])\n",
        "\n",
        "    discriminator = discriminator_model()\n",
        "    d_opt = Adam(lr=1e-5, beta_1=0.1)\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=d_opt)\n",
        "\n",
        "    # generator+discriminator （discriminator部分の重みは固定）\n",
        "    discriminator.trainable = False\n",
        "    generator = generator_model()\n",
        "    dcgan = Sequential([generator, discriminator])\n",
        "    g_opt = Adam(lr=2e-4, beta_1=0.5)\n",
        "    dcgan.compile(loss='binary_crossentropy', optimizer=g_opt)\n",
        "\n",
        "    num_batches = int(X_train.shape[0] / BATCH_SIZE)\n",
        "    print('Number of batches:', num_batches)\n",
        "    for epoch in range(NUM_EPOCH):\n",
        "\n",
        "        for index in range(num_batches):\n",
        "            noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n",
        "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
        "            generated_images = generator.predict(noise, verbose=0)\n",
        "\n",
        "            # 生成画像を出力\n",
        "            if index % 500 == 0:\n",
        "                image = combine_images(generated_images)\n",
        "                image = image*127.5 + 127.5\n",
        "                if not os.path.exists(GENERATED_IMAGE_PATH):\n",
        "                    os.mkdir(GENERATED_IMAGE_PATH)\n",
        "                Image.fromarray(image.astype(np.uint8))\\\n",
        "                    .save(GENERATED_IMAGE_PATH+\"%04d_%04d.png\" % (epoch, index))\n",
        "\n",
        "            # discriminatorを更新\n",
        "            X = np.concatenate((image_batch, generated_images))\n",
        "            y = [1]*BATCH_SIZE + [0]*BATCH_SIZE\n",
        "            d_loss = discriminator.train_on_batch(X, y)\n",
        "\n",
        "            # generatorを更新\n",
        "            noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n",
        "            g_loss = dcgan.train_on_batch(noise, [1]*BATCH_SIZE)\n",
        "            print(\"epoch: %d, batch: %d, g_loss: %f, d_loss: %f\" % (epoch, index, g_loss, d_loss))\n",
        "\n",
        "        generator.save_weights('generator.h5')\n",
        "        discriminator.save_weights('discriminator.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeDkDH-m65iO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}